{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "load_df",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "-- SELECT * from FIRE.PUBLIC.\"fire_df_final\"\nSELECT * from FIRE.PUBLIC.\"FIRE_LONG_LAT\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "to_df",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "fire_df = load_df.to_pandas()\nfire_df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9166bce2-dbd4-4023-8617-4ef53d454f32",
   "metadata": {
    "language": "python",
    "name": "remove_invalid_counties",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "invalid_counties = [\"MEXICO\", \"STATE OF NEVADA\", \"STATE OF OREGON\"] #not counties in ca\nfire_df = fire_df[~fire_df[\"INCIDENT_COUNTY\"].isin(invalid_counties)]\nprint(len(fire_df))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac58a489-703f-4448-9a87-42a30021151b",
   "metadata": {
    "language": "python",
    "name": "find_null",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "missing_data_rows = fire_df[fire_df.isnull().any(axis=1)]\nmissing_data_rows",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00cfaf3b-781e-4be4-b7df-4d4a1fcab5ff",
   "metadata": {
    "language": "python",
    "name": "address_null",
    "collapsed": false,
    "resultHeight": 143
   },
   "outputs": [],
   "source": "fire_df.fillna(0, inplace=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab84a49f-cadf-40d7-9aa3-723c29cf919a",
   "metadata": {
    "language": "python",
    "name": "get_cols",
    "collapsed": false,
    "resultHeight": 172
   },
   "outputs": [],
   "source": "print(fire_df.columns)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac7d2b71-2e38-47a0-b101-113b24b1c28f",
   "metadata": {
    "language": "python",
    "name": "select_features",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "county_col = 'INCIDENT_COUNTY'\n\nselected_features = ['AVG_ACRES_BURNED', 'AVG_TIME_TO_EXTINGUISH', 'AVG_CREWSINVOLVED', 'STATION_COUNT']\n# features_to_normalize = fire_df.drop(columns=[county_col])\nincident_county = fire_df[county_col] #save for later",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcd9dd91-9c79-40ef-9bd7-8a106c326599",
   "metadata": {
    "language": "python",
    "name": "normalize",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnormalized_features = scaler.fit_transform(fire_df[selected_features])\nnormalized_df = pd.DataFrame(normalized_features, columns=selected_features)\nnormalized_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4337a0c-ff89-4d21-bd0f-8fc0d47b0885",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false,
    "resultHeight": 403
   },
   "outputs": [],
   "source": "from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=2, random_state=42)  # Adjust n_clusters based on your use case\nnormalized_df[\"cluster\"] = kmeans.fit_predict(normalized_df)\n\n# View clustering results\n# Add clusters to the original DataFrame\nfire_df[\"cluster\"] = normalized_df[\"cluster\"]\n\nfire_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "293b0f54-e42d-441b-b29e-d63086c0d903",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ffdd7c7-ffeb-4dc2-8bfa-8f6d261c0014",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Count number of counties per cluster\ncluster_counts = fire_df.groupby(\"cluster\").size().reset_index(name=\"count\")\n\n# Plot\nsns.barplot(x=\"cluster\", y=\"count\", data=cluster_counts)\nplt.title(\"Number of Counties per Cluster\")\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cd968d9-722d-4da9-8fe8-6eb471a8465c",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false,
    "resultHeight": 1001
   },
   "outputs": [],
   "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Plot pairplot of selected features colored by cluster labels\nsns.pairplot(fire_df[selected_features + ['cluster']], hue='cluster', palette='Set2', markers=[\"o\", \"s\", \"D\"])\nplt.title(\"Pairplot of Features Colored by Clusters\")\nplt.show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54294cd6-d754-48a0-ac91-d471dbc83474",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "collapsed": false,
    "resultHeight": 41
   },
   "outputs": [],
   "source": "from sklearn.metrics import silhouette_score\n\n# Test multiple values of k\nscores = []\nk_values = range(2, 10)\n\nfor k in k_values:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(normalized_features)\n    score = silhouette_score(normalized_features, labels)\n    scores.append(score)\n\n# Plot the Silhouette Scores\nplt.plot(k_values, scores, marker='o')\nplt.title('Silhouette Score vs. Number of Clusters')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Silhouette Score')\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d7774bd-b4f7-4fb6-91b6-c851f7875580",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "resultHeight": 438
   },
   "outputs": [],
   "source": "fire_df.columns",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e5196e2-92b8-45ec-a25d-0b21c34d6304",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "collapsed": false,
    "resultHeight": 403
   },
   "outputs": [],
   "source": "# from sklearn.cluster import KMeans\n\n# kmeans = KMeans(n_clusters=2, random_state=42)  # Adjust n_clusters based on your use case\n# normalized_df[\"cluster\"] = kmeans.fit_predict(normalized_features)\n\n# # View clustering results\n# normalized_df.head()\n\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=2, random_state=42)  # Adjust n_clusters based on your use case\nnormalized_df[\"cluster\"] = kmeans.fit_predict(normalized_features)\n\n# View clustering results\n# Add clusters to the original DataFrame\nfire_df[\"cluster\"] = normalized_df[\"cluster\"]\n\nfire_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d58fd5e3-8cbf-4ce4-a942-2de8274fee2f",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false,
    "resultHeight": 181
   },
   "outputs": [],
   "source": "# # cluster_stats = fire_df.groupby('cluster').agg(['mean', 'std', 'min', 'max'])\n# # print(cluster_stats)\n# print(fire_df.dtypes)\nnumeric_columns = fire_df.select_dtypes(include='number')\ncluster_stats = fire_df.groupby('cluster')[numeric_columns.columns].agg(['mean', 'std', 'min', 'max'])\ncluster_stats\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1a0b750c-ffe6-4ee2-81ea-51d48cd19586",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "resultHeight": 181,
    "collapsed": false
   },
   "outputs": [],
   "source": "selected_features = ['AVG_ACRES_BURNED', 'AVG_TIME_TO_EXTINGUISH', 'AVG_CREWSINVOLVED', 'STATION_COUNT', 'cluster']\nnew_fire_df = fire_df[selected_features]\n# print(selected_features)\nnumeric_columns = new_fire_df.select_dtypes(include='number')\ncluster_stats = new_fire_df.groupby('cluster')[numeric_columns.columns].agg(['mean'])\ncluster_stats",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e019757-4ebd-46f5-bdf4-82bb8bf6fa9a",
   "metadata": {
    "name": "cell17",
    "collapsed": false,
    "resultHeight": 198
   },
   "source": "notes\n- interactive map that displays clusters\n- work with two main clusters\n- do decision, alt way is to train a model\n- work with LLM's to see how they pan out on a map\n- make a number of fires df"
  }
 ]
}